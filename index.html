<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BCK AI - Voice & Vision Edition</title>
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Font Be Vietnam Pro & JetBrains Mono -->
    <link href="https://fonts.googleapis.com/css2?family=Be+Vietnam+Pro:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;700;800&display=swap" rel="stylesheet">
    <!-- Marked.js for Markdown rendering -->
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: { 
                        sans: ['Be Vietnam Pro', 'sans-serif'], 
                        mono: ['JetBrains Mono', 'monospace'] 
                    },
                    colors: {
                        cyber: {
                            dark: '#020617',
                            panel: '#0f172a',
                            primary: '#06b6d4',
                            glow: '#22d3ee',
                            accent: '#6366f1',
                            text: '#e2e8f0'
                        }
                    },
                    animation: {
                        'pulse-fast': 'pulse 1.5s cubic-bezier(0.4, 0, 0.6, 1) infinite',
                        'message-in': 'fadeIn 0.4s ease-out forwards',
                    },
                    keyframes: {
                        fadeIn: {
                            '0%': { opacity: '0', transform: 'translateY(10px)' },
                            '100%': { opacity: '1', transform: 'translateY(0)' },
                        }
                    }
                }
            }
        }
    </script>

    <style>
        /* --- CLEAN TECH BACKGROUND --- */
        .tech-bg {
            background-color: #020617;
            background-image: 
                radial-gradient(circle at 15% 50%, rgba(6, 182, 212, 0.08) 0%, transparent 25%),
                radial-gradient(circle at 85% 30%, rgba(99, 102, 241, 0.08) 0%, transparent 25%);
        }

        /* --- SCROLLBAR --- */
        ::-webkit-scrollbar { width: 6px; }
        ::-webkit-scrollbar-track { background: transparent; }
        ::-webkit-scrollbar-thumb { background: #1e293b; border-radius: 3px; }
        ::-webkit-scrollbar-thumb:hover { background: #334155; }

        /* --- MARKDOWN STYLES --- */
        .markdown-body { font-size: 0.95rem; line-height: 1.7; color: #e2e8f0; }
        .markdown-body p { margin-bottom: 0.75rem; }
        .markdown-body strong { color: #67e8f9; font-weight: 600; }
        .markdown-body em { color: #a5b4fc; }
        .markdown-body code { 
            font-family: 'JetBrains Mono', monospace; 
            background: rgba(15, 23, 42, 0.8); 
            padding: 0.2em 0.4em; 
            border-radius: 4px; 
            color: #22d3ee; 
            font-size: 0.85em;
        }
        .markdown-body pre { 
            background: #0f172a; 
            padding: 1rem; 
            border-radius: 8px; 
            overflow-x: auto; 
            margin: 0.5rem 0;
            border: 1px solid #1e293b;
        }
        .markdown-body ul { list-style-type: disc; padding-left: 1.5rem; margin-bottom: 0.75rem; }
        .markdown-body ol { list-style-type: decimal; padding-left: 1.5rem; margin-bottom: 0.75rem; }
        .markdown-body a { color: #38bdf8; text-decoration: none; border-bottom: 1px dashed #38bdf8; transition: all 0.2s; }
        .markdown-body a:hover { color: #22d3ee; border-bottom-style: solid; }
        .markdown-body blockquote { 
            border-left: 3px solid #6366f1; 
            padding-left: 1rem; 
            color: #94a3b8; 
            font-style: italic;
            margin: 0.5rem 0;
        }

        .markdown-body img {
            border-radius: 8px;
            max-width: 100%;
            border: 1px solid #334155;
        }

        /* --- UTILITIES --- */
        .glass-panel {
            background: rgba(15, 23, 42, 0.6);
            backdrop-filter: blur(12px);
            border: 1px solid rgba(148, 163, 184, 0.1);
        }
        
        .typing-dot {
            animation: typing 1.4s infinite ease-in-out both;
        }
        .typing-dot:nth-child(1) { animation-delay: -0.32s; }
        .typing-dot:nth-child(2) { animation-delay: -0.16s; }
        @keyframes typing {
            0%, 80%, 100% { transform: scale(0); }
            40% { transform: scale(1); }
        }

        /* Microphone Pulse */
        .mic-active {
            animation: micPulse 1.5s infinite;
            background-color: #ef4444 !important;
            color: white !important;
            border-color: #ef4444 !important;
        }
        @keyframes micPulse {
            0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(239, 68, 68, 0); }
            100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
        }
    </style>
</head>
<body class="tech-bg h-screen flex items-center justify-center font-sans text-cyber-text overflow-hidden selection:bg-cyber-primary selection:text-white">

    <!-- MAIN CONTAINER -->
    <div class="w-full h-full max-w-5xl md:h-[90vh] md:w-[95vw] md:rounded-2xl glass-panel shadow-2xl flex flex-col relative overflow-hidden border border-slate-800/50">
        
        <!-- HEADER -->
        <header class="h-16 px-6 border-b border-slate-800/50 flex items-center justify-between bg-slate-900/50">
            <div class="flex items-center gap-4">
                <div class="w-10 h-10 rounded-full bg-gradient-to-tr from-cyan-500 to-blue-600 flex items-center justify-center shadow-lg shadow-cyan-500/20">
                    <svg class="w-6 h-6 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19.428 15.428a2 2 0 00-1.022-.547l-2.384-.477a6 6 0 00-3.86.517l-.318.158a6 6 0 01-3.86.517L6.05 15.21a2 2 0 00-1.806.547M8 4h8l-1 1v5.172a2 2 0 00.586 1.414l5 5c1.26 1.26.367 3.414-1.415 3.414H4.828c-1.782 0-2.674-2.154-1.414-3.414l5-5A2 2 0 009 10.172V5L8 4z"></path>
                    </svg>
                </div>
                <div>
                    <h1 class="font-bold text-lg tracking-wide text-white flex items-center gap-2">
                        BCK AI <span class="px-1.5 py-0.5 rounded text-[10px] font-mono bg-cyan-500/10 text-cyan-400 border border-cyan-500/20">BOT</span>
                    </h1>
                    <div class="flex items-center gap-2">
                        <span class="relative flex h-2 w-2">
                          <span class="animate-ping absolute inline-flex h-full w-full rounded-full bg-emerald-400 opacity-75"></span>
                          <span class="relative inline-flex rounded-full h-2 w-2 bg-emerald-500"></span>
                        </span>
                        <span class="text-xs text-slate-400 font-mono tracking-wider">Chat Bot Ready</span>
                    </div>
                </div>
            </div>
            
            <button id="clear-btn" class="p-2 rounded-lg hover:bg-slate-800 text-slate-400 hover:text-red-400 transition-colors" title="X√≥a l·ªãch s·ª≠ chat">
                <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 7l-.867 12.142A2 2 0 0116.138 21H7.862a2 2 0 01-1.995-1.858L5 7m5 4v6m4-6v6m1-10V4a1 1 0 00-1-1h-4a1 1 0 00-1 1v3M4 7h16"></path></svg>
            </button>
        </header>

        <!-- CHAT AREA -->
        <div id="chat-container" class="flex-1 overflow-y-auto p-6 space-y-6 scroll-smooth">
            <!-- Bot Welcome Message -->
            <div class="flex gap-4 animate-message-in">
                <div class="w-8 h-8 rounded-full bg-gradient-to-tr from-cyan-500 to-blue-600 flex-shrink-0 flex items-center justify-center mt-1 shadow-md shadow-cyan-500/10">
                    <svg class="w-4 h-4 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 10V3L4 14h7v7l9-11h-7z"></path></svg>
                </div>
                <div class="flex flex-col gap-1 max-w-[85%]">
                    <span class="text-xs font-mono text-cyan-400 font-medium tracking-wider mb-1 flex items-center gap-2">BOT STARTING</span>
                    <div class="p-4 rounded-2xl rounded-tl-none bg-slate-800/80 border border-slate-700/50 shadow-sm backdrop-blur-sm">
                        <div class="markdown-body">
                            <!-- N·ªòI DUNG L·ªúI CH√ÄO -->
                            <p>Ch√†o b·∫°n! üëã M√¨nh l√† <strong>BCK AI</strong>.</p>
                            <p>M√¨nh c√≥ th·ªÉ gi√∫p b·∫°n t√¨m s√°ch, tra c·ª©u th√¥ng tin th∆∞ vi·ªán, ho·∫∑c <strong>tr√≤ chuy·ªán t·ª± do</strong> v·ªÅ b·∫•t c·ª© ch·ªß ƒë·ªÅ g√¨ nh√©! üòâ</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- INPUT AREA -->
        <div class="p-4 border-t border-slate-800/50 bg-slate-900/30 backdrop-blur-md flex flex-col gap-2">
            
            <!-- Preview Image Area (Hidden by default) -->
            <div id="image-preview-container" class="hidden px-2 pb-2">
                <div class="relative inline-block group">
                    <img id="image-preview" src="" alt="Preview" class="h-20 w-auto rounded-lg border border-cyan-500/50 shadow-lg object-cover">
                    <button id="remove-image-btn" class="absolute -top-2 -right-2 bg-red-500 text-white rounded-full p-0.5 hover:bg-red-600 shadow-sm">
                        <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path></svg>
                    </button>
                    <div class="absolute inset-0 bg-black/20 group-hover:bg-transparent transition-colors rounded-lg pointer-events-none"></div>
                </div>
            </div>

            <!-- Input Bar -->
            <div class="relative group w-full">
                <div class="absolute -inset-0.5 bg-gradient-to-r from-cyan-500 to-blue-600 rounded-xl opacity-20 group-hover:opacity-40 transition duration-500 blur"></div>
                <div class="relative flex items-end bg-slate-900 rounded-xl border border-slate-700 p-1.5 focus-within:border-cyan-500/50 transition-colors">
                    
                    <!-- File Upload Button -->
                    <input type="file" id="file-input" accept="image/*" class="hidden">
                    <button id="upload-btn" class="p-3 text-slate-400 hover:text-cyan-400 transition-colors rounded-lg hover:bg-slate-800" title="G·ª≠i ·∫£nh">
                        <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15.172 7l-6.586 6.586a2 2 0 102.828 2.828l6.414-6.586a4 4 0 00-5.656-5.656l-6.415 6.585a6 6 0 108.486 8.486L20.5 13"></path></svg>
                    </button>

                    <textarea 
                        id="user-input" 
                        rows="1" 
                        placeholder="Nh·∫≠p tin nh·∫Øn ho·∫∑c g·ª≠i ·∫£nh..." 
                        class="w-full bg-transparent text-slate-200 placeholder-slate-500 text-sm px-2 py-3 focus:outline-none resize-none max-h-32"
                        oninput="this.style.height = ''; this.style.height = this.scrollHeight + 'px'"></textarea>
                    
                    <!-- Voice Button (Updated with type="button") -->
                    <button type="button" id="voice-btn" class="p-3 text-slate-400 hover:text-cyan-400 transition-colors rounded-lg hover:bg-slate-800 mr-1 group relative" title="Nh·∫≠p b·∫±ng gi·ªçng n√≥i">
                        <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path></svg>
                    </button>

                    <button id="send-btn" class="p-3 rounded-lg bg-cyan-600 hover:bg-cyan-500 text-white shadow-lg shadow-cyan-500/20 transition-all active:scale-95 disabled:opacity-50 disabled:cursor-not-allowed">
                        <svg class="w-5 h-5 transform rotate-90" fill="currentColor" viewBox="0 0 20 20"><path d="M10.894 2.553a1 1 0 00-1.788 0l-7 14a1 1 0 001.169 1.409l5-1.429A1 1 0 009 15.571V11a1 1 0 112 0v4.571a1 1 0 00.725.962l5 1.428a1 1 0 001.17-1.408l-7-14z"></path></svg>
                    </button>
                </div>
            </div>
            <div class="text-center">
                 <div class="text-[10px] font-mono text-slate-600 tracking-widest uppercase">Powered by Gemini 1.5 Flash</div>
            </div>
        </div>

    </div>

    <!-- JAVASCRIPT LOGIC -->
    <script type="module">
        import { GoogleGenerativeAI } from "https://esm.run/@google/generative-ai";

        // --- CONFIGURATION ---
        const API_KEY = "AIzaSyA9R8IIDlBfkk1dOLC1nLsBGYHzRd5CEjI"; 
        
        // --- ADAPTIVE MODEL DISCOVERY ---
        async function getAvailableModels(key) {
            try {
                const listUrl = `https://generativelanguage.googleapis.com/v1beta/models?key=${key}`;
                const response = await fetch(listUrl);
                if (!response.ok) return [];
                const data = await response.json();
                return data.models
                    .filter(m => m.supportedGenerationMethods?.includes("generateContent") 
                              && !m.name.includes("tts") 
                              && !m.name.includes("embedding"))
                    .map(m => m.name.replace("models/", ""));
            } catch (e) {
                console.warn("Failed to fetch models dynamically:", e);
                return [];
            }
        }

        const PRIORITY_MODELS = ['gemini-1.5-flash', 'gemini-1.5-flash-latest', 'gemini-1.5-pro', 'gemini-pro'];

        // DOM Elements
        const chatContainer = document.getElementById('chat-container');
        const userInput = document.getElementById('user-input');
        const sendBtn = document.getElementById('send-btn');
        const clearBtn = document.getElementById('clear-btn');
        
        // New Elements for Voice & Image
        const voiceBtn = document.getElementById('voice-btn');
        const uploadBtn = document.getElementById('upload-btn');
        const fileInput = document.getElementById('file-input');
        const imagePreviewContainer = document.getElementById('image-preview-container');
        const imagePreview = document.getElementById('image-preview');
        const removeImageBtn = document.getElementById('remove-image-btn');

        // State
        let chatHistory = [];
        let isGenerating = false;
        let genAI = null;
        let verifiedModels = [];
        let currentImageBase64 = null; // Store base64 image data
        let currentImageMimeType = null;

        // Init Gemini
        if (API_KEY) {
            genAI = new GoogleGenerativeAI(API_KEY);
            getAvailableModels(API_KEY).then(models => {
                if(models.length > 0) {
                    verifiedModels = PRIORITY_MODELS.filter(p => models.includes(p))
                                    .concat(models.filter(m => !PRIORITY_MODELS.includes(m)));
                    console.log("Verified Models:", verifiedModels);
                }
            });
        }

        // --- VOICE RECOGNITION SETUP (FIXED & ROBUST) ---
        let recognition;
        // Ki·ªÉm tra h·ªó tr·ª£ tr√¨nh duy·ªát
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.continuous = false; // T·∫Øt continuous ƒë·ªÉ tr√°nh l·ªói ng·∫Øt qu√£ng m·∫°ng
            recognition.lang = 'vi-VN'; 
            recognition.interimResults = false;
            recognition.maxAlternatives = 1;

            recognition.onstart = () => {
                voiceBtn.classList.add('mic-active');
                voiceBtn.classList.remove('text-slate-400');
                voiceBtn.classList.add('text-white');
                userInput.placeholder = "ƒêang nghe... (H√£y n√≥i g√¨ ƒë√≥)";
            };

            recognition.onend = () => {
                voiceBtn.classList.remove('mic-active');
                voiceBtn.classList.add('text-slate-400');
                voiceBtn.classList.remove('text-white');
                // Ch·ªâ reset placeholder n·∫øu ch∆∞a c√≥ n·ªôi dung
                if (userInput.placeholder.includes("ƒêang nghe")) {
                    userInput.placeholder = "Nh·∫≠p tin nh·∫Øn ho·∫∑c g·ª≠i ·∫£nh...";
                }
                userInput.focus();
            };

            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                userInput.value += (userInput.value ? ' ' : '') + transcript;
                userInput.style.height = 'auto';
                userInput.style.height = userInput.scrollHeight + 'px';
            };

            // Handle Errors Chi ti·∫øt h∆°n
            recognition.onerror = (event) => {
                console.warn("Speech API Error Detail:", event.error);
                
                voiceBtn.classList.remove('mic-active');
                voiceBtn.classList.add('text-slate-400');
                voiceBtn.classList.remove('text-white');
                
                let errorMsg = "L·ªói mic: " + event.error;
                
                if (event.error === 'network') {
                    errorMsg = "L·ªói k·∫øt n·ªëi d·ªãch v·ª• Gi·ªçng n√≥i.";
                    // Ch·ªâ hi·ªán alert 1 l·∫ßn ƒë·ªÉ kh√¥ng l√†m phi·ªÅn
                    if (!window.hasShownNetworkAlert) {
                        alert("‚ö†Ô∏è L·ªói k·∫øt n·ªëi d·ªãch v·ª• Gi·ªçng n√≥i (Network Error)!\n\nNguy√™n nh√¢n & C√°ch kh·∫Øc ph·ª•c:\n1. T·∫Øt VPN ho·∫∑c AdBlock n·∫øu ƒëang b·∫≠t.\n2. S·ª≠ d·ª•ng tr√¨nh duy·ªát Google Chrome ho·∫∑c Microsoft Edge.\n3. ƒê·∫£m b·∫£o m·∫°ng ·ªïn ƒë·ªãnh.");
                        window.hasShownNetworkAlert = true;
                    }
                } else if (event.error === 'not-allowed' || event.error === 'service-not-allowed') {
                    errorMsg = "Thi·∫øu quy·ªÅn truy c·∫≠p Mic!";
                    alert("‚ö†Ô∏è Vui l√≤ng c·∫•p quy·ªÅn Microphone cho trang web n√†y tr√™n thanh ƒë·ªãa ch·ªâ.");
                } else if (event.error === 'no-speech') {
                    errorMsg = "Kh√¥ng nghe th·∫•y g√¨. Th·ª≠ l·∫°i nh√©!";
                } else if (event.error === 'audio-capture') {
                    errorMsg = "Kh√¥ng t√¨m th·∫•y Microphone.";
                }
                
                userInput.placeholder = errorMsg;
            };

            voiceBtn.addEventListener('click', () => {
                // Ki·ªÉm tra m·∫°ng tr∆∞·ªõc khi b·∫≠t
                if (!navigator.onLine) {
                    alert("B·∫°n ƒëang offline. T√≠nh nƒÉng gi·ªçng n√≥i c·∫ßn k·∫øt n·ªëi m·∫°ng.");
                    return;
                }

                if (voiceBtn.classList.contains('mic-active')) {
                    recognition.stop();
                } else {
                    try {
                        recognition.start();
                    } catch (e) {
                        console.warn("Voice start warning:", e);
                        recognition.stop();
                        setTimeout(() => {
                            try { recognition.start(); } catch (err) {}
                        }, 200); // Th·ª≠ l·∫°i sau 200ms n·∫øu b·ªã k·∫πt
                    }
                }
            });
        } else {
            voiceBtn.style.display = 'none'; // ·∫®n n√∫t n·∫øu tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£
            console.warn("Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ Web Speech API.");
        }

        // --- IMAGE HANDLING ---
        
        // Convert file to Base64
        const fileToBase64 = (file) => {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.readAsDataURL(file);
                reader.onload = () => resolve(reader.result);
                reader.onerror = (error) => reject(error);
            });
        };

        uploadBtn.addEventListener('click', () => fileInput.click());

        fileInput.addEventListener('change', async (e) => {
            const file = e.target.files[0];
            if (!file) return;

            if (!file.type.startsWith('image/')) {
                alert("Vui l√≤ng ch·ªâ ch·ªçn file ·∫£nh.");
                return;
            }

            try {
                const base64Data = await fileToBase64(file);
                currentImageBase64 = base64Data.split(',')[1]; // Remove data:image/png;base64, prefix
                currentImageMimeType = file.type;
                
                // Show preview
                imagePreview.src = base64Data;
                imagePreviewContainer.classList.remove('hidden');
                userInput.focus();
            } catch (error) {
                console.error("Error reading file:", error);
                alert("L·ªói khi ƒë·ªçc file ·∫£nh.");
            }
            
            // Reset input so same file can be selected again if needed
            fileInput.value = '';
        });

        removeImageBtn.addEventListener('click', () => {
            currentImageBase64 = null;
            currentImageMimeType = null;
            imagePreviewContainer.classList.add('hidden');
            imagePreview.src = '';
        });

        // --- CHAT FUNCTIONS ---

        function addMessage(role, text, imageSrc = null) {
            const isUser = role === 'user';
            const msgDiv = document.createElement('div');
            msgDiv.className = `flex gap-4 animate-message-in ${isUser ? 'flex-row-reverse' : ''}`;
            
            const avatar = isUser 
                ? `<div class="w-8 h-8 rounded-full bg-slate-700 flex-shrink-0 flex items-center justify-center mt-1 border border-slate-600"><svg class="w-4 h-4 text-slate-300" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 7a4 4 0 11-8 0 4 4 0 018 0zM12 14a7 7 0 00-7 7h14a7 7 0 00-7-7z"></path></svg></div>`
                : `<div class="w-8 h-8 rounded-full bg-gradient-to-tr from-cyan-500 to-blue-600 flex-shrink-0 flex items-center justify-center mt-1 shadow-md shadow-cyan-500/10"><svg class="w-4 h-4 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 10V3L4 14h7v7l9-11h-7z"></path></svg></div>`;

            const label = isUser 
                ? '' 
                : `<span class="text-xs font-mono text-cyan-400 font-medium tracking-wider mb-1 flex items-center gap-2">BCK AI</span>`;

            const bubbleClass = isUser
                ? "bg-cyan-600/20 border border-cyan-500/30 text-cyan-50 rounded-tr-none"
                : "bg-slate-800/80 border border-slate-700/50 text-slate-200 rounded-tl-none shadow-sm backdrop-blur-sm";

            const contentHtml = isUser 
                ? `<p>${escapeHtml(text)}</p>` 
                : marked.parse(text);

            let imageHtml = '';
            if (imageSrc) {
                imageHtml = `<div class="mb-2"><img src="${imageSrc}" class="rounded-lg max-h-48 border border-white/10" alt="User upload"></div>`;
            }

            msgDiv.innerHTML = `
                ${avatar}
                <div class="flex flex-col gap-1 max-w-[85%] ${isUser ? 'items-end' : 'items-start'}">
                    ${label}
                    <div class="p-3.5 px-5 rounded-2xl ${bubbleClass} text-sm leading-relaxed overflow-hidden">
                        ${imageHtml}
                        <div class="markdown-body">${contentHtml}</div>
                    </div>
                </div>
            `;

            chatContainer.appendChild(msgDiv);
            scrollToBottom();
        }

        function showTypingIndicator() {
            const id = 'typing-' + Date.now();
            const div = document.createElement('div');
            div.id = id;
            div.className = 'flex gap-4 animate-message-in';
            div.innerHTML = `
                <div class="w-8 h-8 rounded-full bg-gradient-to-tr from-cyan-500 to-blue-600 flex-shrink-0 flex items-center justify-center mt-1 opacity-50">
                    <svg class="w-4 h-4 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 10V3L4 14h7v7l9-11h-7z"></path></svg>
                </div>
                <div class="flex flex-col gap-1">
                    <div class="p-4 rounded-2xl rounded-tl-none bg-slate-800/50 border border-slate-700/30 w-16 h-10 flex items-center justify-center gap-1">
                        <div class="w-1.5 h-1.5 bg-cyan-400 rounded-full typing-dot"></div>
                        <div class="w-1.5 h-1.5 bg-cyan-400 rounded-full typing-dot"></div>
                        <div class="w-1.5 h-1.5 bg-cyan-400 rounded-full typing-dot"></div>
                    </div>
                </div>
            `;
            chatContainer.appendChild(div);
            scrollToBottom();
            return id;
        }

        function removeTypingIndicator(id) {
            const el = document.getElementById(id);
            if (el) el.remove();
        }

        function scrollToBottom() {
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }

        function getMockResponse(text) {
            return "Ch·∫ø ƒë·ªô Offline: " + text;
        }

        // --- CORE GENERATION LOGIC (UPDATED FOR MULTIMODAL) ---
        async function generateContentWithFallback(userMessage, imageBase64 = null, imageMime = null) {
            if (!genAI) return { text: getMockResponse(userMessage), usedModel: "MockMode (No Key)" };

            let modelsToTry = verifiedModels.length > 0 ? verifiedModels : PRIORITY_MODELS;
            if (modelsToTry.length === 0) modelsToTry = ['gemini-1.5-flash'];

            let errors = [];

            for (const modelName of modelsToTry) {
                try {
                    const model = genAI.getGenerativeModel({ model: modelName });
                    
                    // Construct Payload
                    let parts = [];
                    if (userMessage) parts.push({ text: userMessage });
                    
                    if (imageBase64 && imageMime) {
                        // Ensure model supports vision (Flash and Pro do, standard Pro 1.0 does not)
                        // But we will try anyway, catch error if model is text-only
                        parts.push({
                            inlineData: {
                                data: imageBase64,
                                mimeType: imageMime
                            }
                        });
                    }

                    // Note: For multimodal in single turn, we use generateContent directly without chat history
                    // If text-only, we can use startChat for history.
                    // To keep it simple & robust: if image exists, we do single-turn generateContent (stateless for that turn).
                    // If no image, we do stateful chat.
                    
                    let text = "";
                    
                    if (imageBase64) {
                        const result = await model.generateContent(parts);
                        const response = await result.response;
                        text = response.text();
                    } else {
                        const chat = model.startChat({ history: chatHistory, generationConfig: { maxOutputTokens: 1000 } });
                        const result = await chat.sendMessage(userMessage);
                        const response = await result.response;
                        text = response.text();
                    }

                    return { text, usedModel: modelName };

                } catch (e) {
                    let cleanMsg = e.message || "Unknown error";
                    if(cleanMsg.includes("404")) cleanMsg = "Not Found (404)";
                    else if(cleanMsg.includes("429")) cleanMsg = "Rate Limit (429)";
                    else if(cleanMsg.includes("400")) cleanMsg = "Bad Request (400) - Maybe model doesn't support images";
                    errors.push(`${modelName}: ${cleanMsg}`);
                }
            }
            
            console.error("All API models failed.", errors);
            return { 
                text: "Xin l·ªói, m√¨nh kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi m√°y ch·ªß AI l√∫c n√†y. (Ki·ªÉm tra l·∫°i Key ho·∫∑c M·∫°ng)", 
                usedModel: "MockMode",
                errors: errors 
            };
        }

        async function handleSend() {
            const text = userInput.value.trim();
            // Allow sending if text OR image exists
            if ((!text && !currentImageBase64) || isGenerating) return;

            // Prepare sending data
            const sentText = text;
            const sentImageBase64 = currentImageBase64;
            const sentImageMime = currentImageMimeType;
            const displayImageSrc = sentImageBase64 ? `data:${sentImageMime};base64,${sentImageBase64}` : null;

            // UI Updates
            userInput.value = '';
            userInput.style.height = 'auto';
            
            // Clear preview immediately
            currentImageBase64 = null;
            currentImageMimeType = null;
            imagePreviewContainer.classList.add('hidden');
            imagePreview.src = '';

            addMessage('user', sentText, displayImageSrc);
            isGenerating = true;
            sendBtn.disabled = true;

            const typingId = showTypingIndicator();

            try {
                const result = await generateContentWithFallback(sentText || "M√¥ t·∫£ b·ª©c ·∫£nh n√†y", sentImageBase64, sentImageMime);
                let responseText = result.text;

                removeTypingIndicator(typingId);
                
                if (result.usedModel.startsWith("MockMode")) {
                    const warning = `<span class="text-[10px] text-amber-400 bg-amber-900/30 border border-amber-500/20 px-2 py-1 rounded mb-2 inline-block font-mono">‚ö†Ô∏è CH·∫æ ƒê·ªò OFFLINE</span><br>`;
                    addMessage('bot', warning + responseText);
                } else {
                    addMessage('bot', responseText);
                }
                
                // Only push to history if text-only to maintain context flow easily
                if (!sentImageBase64) {
                    chatHistory.push({ role: "user", parts: [{ text: sentText }] });
                    chatHistory.push({ role: "model", parts: [{ text: responseText }] });
                }

            } catch (error) {
                console.error("Critical Error:", error);
                removeTypingIndicator(typingId);
                addMessage('bot', "‚ö†Ô∏è L·ªói h·ªá th·ªëng nghi√™m tr·ªçng.");
            } finally {
                isGenerating = false;
                sendBtn.disabled = false;
                userInput.focus();
            }
        }

        // --- EVENT LISTENERS ---
        
        sendBtn.addEventListener('click', handleSend);
        
        userInput.addEventListener('keydown', (e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                handleSend();
            }
        });

        clearBtn.addEventListener('click', () => {
            chatContainer.innerHTML = '';
            // N·ªòI DUNG L·ªúI CH√ÄO KHI X√ìA L·ªäCH S·ª¨ C≈®NG ƒê∆Ø·ª¢C C·∫¨P NH·∫¨T
            const greetingHTML = `
            <div class="flex gap-4 animate-message-in">
                <div class="w-8 h-8 rounded-full bg-gradient-to-tr from-cyan-500 to-blue-600 flex-shrink-0 flex items-center justify-center mt-1 shadow-md shadow-cyan-500/10">
                    <svg class="w-4 h-4 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 10V3L4 14h7v7l9-11h-7z"></path></svg>
                </div>
                <div class="flex flex-col gap-1 max-w-[85%]">
                    <span class="text-xs font-mono text-cyan-400 font-medium tracking-wider mb-1 flex items-center gap-2">BOT STARTING</span>
                    <div class="p-4 rounded-2xl rounded-tl-none bg-slate-800/80 border border-slate-700/50 shadow-sm backdrop-blur-sm">
                        <div class="markdown-body">
                            <p>Ch√†o b·∫°n! üëã M√¨nh l√† <strong>BCK AI</strong>.</p>
                            <p>M√¨nh c√≥ th·ªÉ gi√∫p b·∫°n t√¨m s√°ch, tra c·ª©u th√¥ng tin th∆∞ vi·ªán, ho·∫∑c <strong>tr√≤ chuy·ªán t·ª± do</strong> v·ªÅ b·∫•t c·ª© ch·ªß ƒë·ªÅ g√¨ nh√©! üòâ</p>
                        </div>
                    </div>
                </div>
            </div>`;
            chatContainer.innerHTML = greetingHTML;
            chatHistory = [];
        });

    </script>
</body>
</html>


